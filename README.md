# mamn01-project
Project for the Advanced Interaction Design (MAMN01) at LTH

## Weeklog
### Week 1
This week we started by presenting the idea for our application for the rest of the group.
We also finished our low fi prototype. 

![alt tag](https://raw.github.com/dabbe/mamn01-project/master/images/lowfi.jpg)

We decided on using 5 screens for the application. The inital screen which only has a start button. We also discussed having a level picker at this screen, but this wont be implemented unless we feel we have time left in the end of the project. The second screen consist of the search-for-the-treasure-part of the game, which we decided will be a compass. The screen will also show the over all progress, in a bar. This is where the player collects their total points. 

The two next screens are the digging and blowing screens, which are very similar and gives the user two very different way of interacting with the game. The last screen will consist of a quiz. We decided this quiz will be in the form of a multiple choice test, which the user has to pass to get the treasure.

### Week 2
We distributed the responsibility of each screen to one member of the group: 
* Daniel had the navigation screen.
* Oscar had the digging screen.
* Jacob had the blowing screen.
* Christian had the Quiz screen. 
We have come far and we are a bit puzzled by how far we have come. Every screen has its core functionality working. (reading sensors). It was decided that the navigation would use the Fused Location API from Android to get the best possible location data. We have not implemented any distance indicators but we are going to. The question is really, what kind of feedback gives the best understanding of the situation? Haptic, colors, sound?.

The digging screen uses the gyroscope to look for changes in tilting of the device. It has not been decided exactly how the movement will be but we have tried a few which all works. 
 
